% !TeX spellcheck = en_GB
\documentclass[12pt,fleqn]{article}

\usepackage[english]{babel}
\usepackage{SpeedyGonzales}
\usepackage{MediocreMike}
%\usepackage{Blastoise}

\title{Image Segmentation}
\author{}
\date{\today}

\pagestyle{fancy}
\fancyhf{}
\lhead{Asger Schultz, s183912}
\chead{}
\rhead{}
\rfoot{Side \thepage{} af \pageref{LastPage}}

\graphicspath{{Billeder/}}
\linespread{1.15}


%\numberwithin{equation}{section}
%\numberwithin{footnote}{section}
%\numberwithin{figure}{section}
%\numberwithin{table}{section}

\begin{document}

%\maketitle
%\thispagestyle{fancy}

\begin{titlepage}
	\begin{center}
		\textsc{\LARGE Image Segmentation}\\
		[1.0cm]
		{
		\large
		\begin{tabular}{lr}
			Anders Henriksen&s183904\\
			Asger Schultz&s183912\\
			Oskar Wiese&\\
			Mads Andersen&\\
			Søren Winkel Holm&s183911
		\end{tabular}
		}\\
		[0.5cm]
		\textsc{\large \today}
	\end{center}
\end{titlepage}
\tableofcontents \newpage

\section{Abstract}
\section{Introduction}
\subsection{Brief overview of data}
Our data consist of one large, high resolution orthomosaic photo of a sugar cane field formatted as a RGB image. The field has been manually labelled by expert biologist to create a human-ground truth, these labels are represented as a GT-matrix with 3 possible classes. Each pixel is either classified as a crop row (green), weed (yellow), background (red). The large photo is cropped into smaller images and afterwards augmentation techniques are used to gain more data. We will return to the augmentation part later. The images with exclusively black pixels are removed from our data set, and images with some black pixels are ignored when calculating the loss function 

\section{Methods}
Netværket blev initialiseret


\subsection{Unification of cropped image predictions}
In a real-world application of the segmentation a farmer would want a complete and precise segmentation of his whole field at once, such that fertilization and pesticides can be distributed accordingly. However, it turns out that the prediction quality is of less quality near the boarders of the image. Therefore, a naïve stitching of the cropped images leads to a full-blown image prediction with obvious flaws near the boarders between the cropped images. To solve this problem, we have chosen to increase the size of the cropped images, and infer on these enlarged pictured. In the procedure of joining the enlarged cropped pictures the pictures are cropped again, to avoid the near border areas. This is computationally inefficient, but it works, and since the inference time is not that big, it is an alright solution. For industrial purposes, another approach might be beneficial.
\section{Results}



\section{Discussion}

\subsection{Extension of network}
SegNet might be promising in our use case, however when including a lot of classes the results are quite bad: (http://mi.eng.cam.ac.uk/projects/segnet/) 
\end{document}



















