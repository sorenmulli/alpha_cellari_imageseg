{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "colab": {
      "name": "imgseg.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qi3HPhhvXY1q"
      },
      "outputs": [],
      "source": [
        "# Implementation of SegNet on Drone Images \n",
        "\n",
        "This notebook recreates the procedure of data preperation and data loading and also initializing, training and evaluating SegNet on this data.\n",
        "\n",
        "As the code is organized in modules, large portions of the produced code is not contained directly herein, but can be consulted by opening the `.py` files in the `src/`-folder.\n",
        "\n",
        "NOTE: Because the full network takes upwards of 30 GB of memory to train and evaluate, a simplified version is used here. The full version can be accessed by setting the `use_simple` variable to `False`. Runtime evaluation is also disabled by default to save memory. It is explained how to enable it further down."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "!echo \"Make sure that you are in /src before running this notebook\"\n",
        "!pwd  # Prints current path (Linux and MacOS only)\n",
        "\n",
        "# For running on google colab\n",
        "# %cd /content\n",
        "# !git clone https://github.com/sorenmulli/alpha_cellari_imageseg.git\n",
        "# %cd alpha_cellari_imageseg/src\n",
        "# %mkdir logs\n",
        "# %pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Hw8PKduCXY14"
      },
      "outputs": [],
      "source": [
        "## Data preperation\n",
        "\n",
        "Downloads and prepares data. This will take a number of minutes to run and requires a little over a gigabyte of storage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m pip install wget --user\n",
        "!python data_prepper.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tLEfk1FRXY2A"
      },
      "outputs": [],
      "source": [
        "## Preparing network training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "from logger import Logger\n",
        "from train import Trainer\n",
        "from model_test import Tester\n",
        "from augment import Augmenter, AugmentationConfig, flip_lr, flip_tb\n",
        "import torch\n",
        "\n",
        "print(\"Configuring parameters...\")\n",
        "\n",
        "# If True, a simpler version of segnet is used\n",
        "use_simple = True\n",
        "\n",
        "# Configuration of network architechture\n",
        "architecture = {\n",
        "\t\t\"kernel_size\":  3,\n",
        "\t\t\"padding\": 1, \n",
        "\t\t\"stride\": 1,\n",
        "\t\t\"pool_dims\": (2, 2),\n",
        "\t\t\"probs\": 0.1,\n",
        "\t\t\"reduce_complexity\": use_simple,\n",
        "}\n",
        "\n",
        "learning_rate = 1.5e-4\n",
        "batch_size = 3\n",
        "epochs = 3000\n",
        "\n",
        "# Configuration of data augmentation\n",
        "# Reducing cropsize significantly reduces memory usage and training time\n",
        "augmentations = AugmentationConfig(\n",
        "    augments =  [flip_lr, flip_tb],  \n",
        "    cropsize = (350, 350),\n",
        "    augment_p = [0.5, 0.5]\n",
        ")\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "logger = Logger(\"logs/train_run.log\", \"Running full training loop\")\n",
        "\n",
        "print(\"Done configuring\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3YOY6Z86XY2H"
      },
      "outputs": [],
      "source": [
        "## Training the Network\n",
        "\n",
        "The following code trains the network.\n",
        "\n",
        "Because we had access to significant compute recourses, we did not optimize the loss calculations for memory. It is therefore not possible to run evaluation on most machines, so it is disabled by default. It can be enabled by setting the `with_loss` argument to `True`. The loss curve is available in the report."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer = Trainer(\"local_data/prep_out.json\", logger)\n",
        "net = trainer.model_trainer(architecture, learning_rate, augmentations, epochs, batch_size, val_every = 25, with_loss = False, save_every = 500)\n",
        "net.save('model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qrHbQtx-XY2O"
      },
      "outputs": [],
      "source": [
        "\n",
        "## Evaluating the Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "G64U3ODUXY2Q"
      },
      "outputs": [],
      "source": [
        "from model import Net\n",
        "# Load model or use existing\n",
        "# net = Net.from_model(\"model\")\n",
        "tester = Tester(\"local_data/prep_out.json\", logger)\n",
        "tester.test_model(net, \"local_data/test\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b9S4CYyrXY2T"
      },
      "outputs": [],
      "source": [
        "## Reconstructing the image\n",
        "\n",
        "In the following, a complete forwarding is carried out using oversampling to prevent borders at the croppings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "pkqZXm55XY2W"
      },
      "outputs": [],
      "source": [
        "from forward_passer import full_forward\n",
        "full_forward(net, None, True, \"local_data/full-forward.png\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "W0SI8vp4cOLN"
      },
      "outputs": [],
      "source": []
    }
  ]
}