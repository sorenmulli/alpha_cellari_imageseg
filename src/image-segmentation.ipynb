{"cells":[{"cell_type":"markdown","execution_count":3,"metadata":{},"outputs":[],"source":["# Implementation of SegNet on Drone Images \n","\n","This notebook recreates the procedure of data preperation and data loading and also initializing, training and evaluating SegNet on this data.\n","\n","As the code is organized in modules, large portions of the produced code is not contained directly herein, but can be consulted by opening the `.py` files in the `src/`-folder.\n","\n","NOTE: Because the full network takes upwards of 30 GB of memory to train, a simplified version is used here. The full version can be accessed by setting the `use_simple` variable to `False`."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Make sure that you are in /src before running this notebook\n/home/sorenwh/Nextcloud/semester3/DL/afl/alpha_cellari_imageseg\n"}],"source":["!echo \"Make sure that you are in /src before running this notebook\"\n","!pwd  # Prints current path (Linux and MacOS only)"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["## Data preperation\n","\n","Downloads and prepares data. This will take a number of minutes to run and requires a little over a gigabyte of storage."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Requirement already satisfied: wget in /home/asger/anaconda3/lib/python3.7/site-packages (3.2)\n2019-12-29 09:56:40.126691\tPreparation of data with images of shape (512, 512, 3)\n\n2019-12-29 09:56:40.126819\tDownloading images...\n2019-12-29 09:56:40.126883\tDone downloading images to paths\n                          \tlocal_data/raw.png\n                          \tlocal_data/target.png\n\n2019-12-29 09:56:40.126925\tLoading images...\n2019-12-29 09:56:42.401438\tDone loading images\n                          \tShapes: (6815, 5364, 3)\n                          \tSplit: (0.83, 0.17)\n\n2019-12-29 09:56:42.401571\tPadding images...\n2019-12-29 09:56:43.272500\tDone padding images\n                          \tShapes: (7168, 5632, 3)\n\n2019-12-29 09:56:43.272657\tSaving subimages to location local_data/imgs/{type}-{index}.png\n2019-12-29 09:56:59.591820\tDone saving subimages\n\n2019-12-29 09:56:59.592804\tStandardizing aerial image...\n2019-12-29 09:56:59.594032\tDone standardizing image\n\n2019-12-29 09:56:59.594258\tSqueezing target images to single channel...\n2019-12-29 10:01:15.062393\tDone creating target values.\n                          \tClasses including void (if any) last:\n                          \t000255000\n                          \t255000000\n                          \t255255000\n                          \t000000000\n\n2019-12-29 10:01:15.064041\tSplitting images...\n2019-12-29 10:01:16.655965\tDone splitting images\n                          \tNumber of images: 154\n                          \tShapes: (512, 512, 3)\n\n2019-12-29 10:01:16.656136\tDetecting void images...\n2019-12-29 10:01:16.785640\tDone finding voids\n                          \t46 images where voids\n\n2019-12-29 10:01:16.785811\tTransposing images to PyTorch's preferred format...\n2019-12-29 10:01:16.785915\tImages transposed. Shape: (154, 3, 512, 512)\n\n2019-12-29 10:01:16.786003\tSaving images...\n2019-12-29 10:01:30.147407\tSaved aerial images to 'local_data/aerial_prepared' and target images to 'local_data/target_prepared.npy'\n\n2019-12-29 10:01:30.147593\tSplitting images into train, validation, test, and voids...\n2019-12-29 10:01:30.151045\tDone splitting images\n                          \tTrain: 69 images\n                          \tValidation: 15 images\n                          \tTest: 24 images\n                          \tVoid: 46 images\n\n2019-12-29 10:01:30.151237\tSaving data preparation output...\n2019-12-29 10:01:30.152164\tDone saving output to 'local_data/prep_out.json'\n\n2019-12-29 10:01:30.152291\tDone preparing data\n\n"}],"source":["!python -m pip install wget\n","!python data_prepper.py"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["## Preparing network training\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["from logger import Logger\n","from train import Trainer\n","from augment import Augmenter, AugmentationConfig, flip_lr, flip_tb\n","import torch\n","\n","# If True, a simpler version of segnet is used\n","use_simple = True\n","\n","# Configuration of network architechture\n","architecture = {\n","\t\t\"kernel_size\":  3,\n","\t\t\"padding\": 1, \n","\t\t\"stride\": 1,\n","\t\t\"pool_dims\": (2, 2),\n","\t\t\"probs\": 0.1,\n","\t\t\"reduce_complexity\": use_simple,\n","}\n","\n","learning_rate = 1.5e-4\n","batch_size = 3\n","epochs = 3000\n","\n","# Configuration of data augmentation\n","# Reducing cropsize significantly reduces memory usage and training time\n","augmentations = AugmentationConfig(\n","    augments =  [flip_lr, flip_tb],  \n","    cropsize = (256, 256), \n","    augment_p = [0.5, 0.5]\n",")\n","\n","torch.cuda.empty_cache()"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["## Training the Network\n","\n","The following code trains the network."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"2019-12-29 10:30:57.826623\tRunning full training loop\n\n2019-12-29 10:30:59.866066\tAugmentations: <class 'augment.AugmentationConfig'>\n2019-12-29 10:30:59.866465\tCriterion and optimizer: CrossEntropyLoss()\n                          \tAdam (\n                          \tParameter Group 0\n                          \t    amsgrad: False\n                          \t    betas: (0.9, 0.999)\n                          \t    eps: 1e-08\n                          \t    lr: 0.00015\n                          \t    weight_decay: 0\n                          \t)\n2019-12-29 10:31:00.513109\tTrain size: 69\n                          \tEval size: 15\n                          \tTest size: 24\n\n2019-12-29 10:31:00.514248\tNeural network information\n                          \t\tNet(\n                          \t  (encoder1): EncoderBlock(\n                          \t    (encoder): Sequential(\n                          \t      (0): BlueLayer(\n                          \t        (convolutional): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0, inplace=False)\n                          \t        (bnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t      (1): BlueLayer(\n                          \t        (convolutional): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0.1, inplace=False)\n                          \t        (bnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t    )\n                          \t    (mpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n                          \t  )\n                          \t  (encoder2): EncoderBlock(\n                          \t    (encoder): Sequential(\n                          \t      (0): BlueLayer(\n                          \t        (convolutional): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0, inplace=False)\n                          \t        (bnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t      (1): BlueLayer(\n                          \t        (convolutional): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0.1, inplace=False)\n                          \t        (bnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t    )\n                          \t    (mpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n                          \t  )\n                          \t  (encoder3): EncoderBlock(\n                          \t    (encoder): Sequential(\n                          \t      (0): BlueLayer(\n                          \t        (convolutional): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0, inplace=False)\n                          \t        (bnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t      (1): BlueLayer(\n                          \t        (convolutional): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0, inplace=False)\n                          \t        (bnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t      (2): BlueLayer(\n                          \t        (convolutional): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0.1, inplace=False)\n                          \t        (bnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t    )\n                          \t    (mpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n                          \t  )\n                          \t  (decoder3): DecoderBlock(\n                          \t    (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n                          \t    (decoder): Sequential(\n                          \t      (0): BlueLayer(\n                          \t        (convolutional): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0, inplace=False)\n                          \t        (bnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t      (1): BlueLayer(\n                          \t        (convolutional): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0, inplace=False)\n                          \t        (bnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t      (2): BlueLayer(\n                          \t        (convolutional): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0.1, inplace=False)\n                          \t        (bnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t    )\n                          \t  )\n                          \t  (decoder4): DecoderBlock(\n                          \t    (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n                          \t    (decoder): Sequential(\n                          \t      (0): BlueLayer(\n                          \t        (convolutional): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0, inplace=False)\n                          \t        (bnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t      (1): BlueLayer(\n                          \t        (convolutional): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0.1, inplace=False)\n                          \t        (bnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t    )\n                          \t  )\n                          \t  (decoder5): DecoderBlock(\n                          \t    (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n                          \t    (decoder): Sequential(\n                          \t      (0): BlueLayer(\n                          \t        (convolutional): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0, inplace=False)\n                          \t        (bnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t      (1): BlueLayer(\n                          \t        (convolutional): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0.1, inplace=False)\n                          \t        (bnorm): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t    )\n                          \t  )\n                          \t)\n2019-12-29 10:31:00.514497\tNumber of epochs 4000 with batch size: 3\n"}],"source":["logger = Logger(\"logs/train_run.log\", \"Running full training loop\")\n","trainer = Trainer(\"local_data/prep_out.json\", logger)\n","net = trainer.model_trainer(architecture, learning_rate, augmentations, epochs, batch_size, val_every = 25, save_every = 500)\n","net.save('model')"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["\n","## Evaluating the Network"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tester = Tester(\"local_data/prep_out.json\", logger)\n","tester.test_model(net, \"local_data/test\")\n"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["## Reconstructing the image\n","\n","In the following, a complete forwarding is carried out using oversampling to prevent borders at the croppings."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["full_forward(net, None, True, \"local_data/full-forward.png\")\n"]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.3"},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}