{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "colab": {
      "name": "imgseg.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qi3HPhhvXY1q"
      },
      "source": [
        "# Implementation of SegNet on Drone Images \n",
        "\n",
        "This notebook recreates the procedure of data preperation and data loading and also initializing, training and evaluating SegNet on this data.\n",
        "\n",
        "As the code is organized in modules, large portions of the produced code is not contained directly herein, but can be consulted by opening the `.py` files in the `src/`-folder.\n",
        "\n",
        "NOTE: Because the full network takes upwards of 30 GB of memory to train and evaluate, a simplified version is used here. The full version can be accessed by setting the `use_simple` variable to `False`. Runtime evaluation is also disabled by default to save memory. It is explained how to enable it further down.\n",
        "\n",
        "We recommend running this notebook on Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\"Make sure that you are in /src before running this notebook\"\n'pwd' is not recognized as an internal or external command,\noperable program or batch file.\n"
        }
      ],
      "source": [
        "!echo \"Make sure that you are in /src before running this notebook\"\n",
        "!pwd  # Prints current path (Linux and MacOS only)\n",
        "\n",
        "# For running on google colab\n",
        "# %cd /content\n",
        "# !git clone https://github.com/sorenmulli/alpha_cellari_imageseg.git\n",
        "# %cd alpha_cellari_imageseg/src\n",
        "# %mkdir logs\n",
        "# %pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Hw8PKduCXY14"
      },
      "source": [
        "## Data preperation\n",
        "\n",
        "Downloads and prepares data. This will take a number of minutes to run and requires a little over a gigabyte of storage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Requirement already satisfied: wget in c:\\users\\asger\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (3.2)\n2020-01-03 20:04:42.989258\tPreparation of data with images of shape (512, 512, 3)\n\n2020-01-03 20:04:42.990221\tDownloading images...\n2020-01-03 20:04:52.757543\tDone downloading images to paths\n                          \tlocal_data/raw.png\n                          \tlocal_data/target.png\n\n2020-01-03 20:04:52.758541\tLoading images...\n2020-01-03 20:04:55.065867\tDone loading images\n                          \tShapes: (6815, 5364, 3)\n                          \tSplit: (0.83, 0.17)\n\n2020-01-03 20:04:55.066870\tPadding images...\n2020-01-03 20:04:56.075968\tDone padding images\n                          \tShapes: (7168, 5632, 3)\n\n2020-01-03 20:04:56.086904\tSaving subimages to location local_data/imgs/{type}-{index}.png\n2020-01-03 20:05:15.751248\tDone saving subimages\n\n2020-01-03 20:05:15.752246\tStandardizing aerial image...\n2020-01-03 20:05:15.755237\tDone standardizing image\n\n2020-01-03 20:05:15.755237\tSqueezing target images to single channel...\n2020-01-03 20:09:12.988029\tDone creating target values.\n                          \tClasses including void (if any) last:\n                          \t000255000\n                          \t255000000\n                          \t255255000\n                          \t000000000\n\n2020-01-03 20:09:12.988029\tSplitting images...\n2020-01-03 20:09:15.358958\tDone splitting images\n                          \tNumber of images: 154\n                          \tShapes: (512, 512, 3)\n\n2020-01-03 20:09:15.358958\tDetecting void images...\n2020-01-03 20:09:15.468620\tDone finding voids\n                          \t46 images where voids\n\n2020-01-03 20:09:15.469618\tTransposing images to PyTorch's preferred format...\n2020-01-03 20:09:15.469618\tImages transposed. Shape: (154, 3, 512, 512)\n\n2020-01-03 20:09:15.469618\tSaving images...\n2020-01-03 20:09:29.161884\tSaved aerial images to 'local_data/aerial_prepared' and target images to 'local_data/target_prepared.npy'\n\n2020-01-03 20:09:29.162881\tSplitting images into train, validation, test, and voids...\n2020-01-03 20:09:29.167866\tDone splitting images\n                          \tTrain: 69 images\n                          \tValidation: 15 images\n                          \tTest: 24 images\n                          \tVoid: 46 images\n\n2020-01-03 20:09:29.167866\tSaving data preparation output...\n2020-01-03 20:09:29.170859\tDone saving output to 'local_data/prep_out.json'\n\n2020-01-03 20:09:29.171855\tDone preparing data\n\n"
        }
      ],
      "source": [
        "!python -m pip install wget --user\n",
        "!python data_prepper.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tLEfk1FRXY2A"
      },
      "source": [
        "## Preparing network training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Configuring parameters...\n2020-01-03 20:10:11.252408\tRunning full training loop\n\nDone configuring\n"
        }
      ],
      "source": [
        "from logger import Logger\n",
        "from train import Trainer\n",
        "from model_test import Tester\n",
        "from augment import Augmenter, AugmentationConfig, flip_lr, flip_tb\n",
        "import torch\n",
        "\n",
        "print(\"Configuring parameters...\")\n",
        "\n",
        "# If True, a simpler version of segnet is used\n",
        "use_simple = True\n",
        "\n",
        "# Configuration of network architechture\n",
        "architecture = {\n",
        "\t\t\"kernel_size\":  3,\n",
        "\t\t\"padding\": 1, \n",
        "\t\t\"stride\": 1,\n",
        "\t\t\"pool_dims\": (2, 2),\n",
        "\t\t\"probs\": 0.1,\n",
        "\t\t\"reduce_complexity\": use_simple,\n",
        "}\n",
        "\n",
        "learning_rate = 1.5e-4\n",
        "batch_size = 3\n",
        "epochs = 3000\n",
        "\n",
        "# Configuration of data augmentation\n",
        "# Reducing cropsize significantly reduces memory usage and training time\n",
        "augmentations = AugmentationConfig(\n",
        "    augments =  [flip_lr, flip_tb],  \n",
        "    cropsize = (350, 350),\n",
        "    augment_p = [0.5, 0.5]\n",
        ")\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "logger = Logger(\"logs/train_run.log\", \"Running full training loop\")\n",
        "\n",
        "print(\"Done configuring\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3YOY6Z86XY2H"
      },
      "source": [
        "## Training the Network\n",
        "\n",
        "The following code trains the network.\n",
        "\n",
        "Because we had access to significant compute recourses, we did not optimize the loss calculations for memory. It is therefore not possible to run evaluation on most machines, so it is disabled by default. It can be enabled by setting the `with_loss` argument to `True`. The loss curve is available in the report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "2020-01-03 20:10:17.950306\tAugmentations: {'cropsize': (350, 350), 'augments': [<function flip_lr at 0x000001C2D4CBED38>, <function flip_tb at 0x000001C2D3400CA8>], 'augment_p': [0.5, 0.5]}\n2020-01-03 20:10:17.954296\tCriterion and optimizer: CrossEntropyLoss()\n                          \tAdam (\n                          \tParameter Group 0\n                          \t    amsgrad: False\n                          \t    betas: (0.9, 0.999)\n                          \t    eps: 1e-08\n                          \t    lr: 0.00015\n                          \t    weight_decay: 0\n                          \t)\n2020-01-03 20:10:18.579215\tTrain size: 69\n                          \tEval size: 15\n                          \tTest size: 24\n\n2020-01-03 20:10:18.583206\tNeural network information\n                          \t\tNet(\n                          \t  (encoder1): EncoderBlock(\n                          \t    (encoder): Sequential(\n                          \t      (0): BlueLayer(\n                          \t        (convolutional): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0, inplace=False)\n                          \t        (bnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t      (1): BlueLayer(\n                          \t        (convolutional): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0.1, inplace=False)\n                          \t        (bnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t    )\n                          \t    (mpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n                          \t  )\n                          \t  (encoder2): EncoderBlock(\n                          \t    (encoder): Sequential(\n                          \t      (0): BlueLayer(\n                          \t        (convolutional): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0, inplace=False)\n                          \t        (bnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t      (1): BlueLayer(\n                          \t        (convolutional): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0.1, inplace=False)\n                          \t        (bnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t    )\n                          \t    (mpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n                          \t  )\n                          \t  (encoder3): EncoderBlock(\n                          \t    (encoder): Sequential(\n                          \t      (0): BlueLayer(\n                          \t        (convolutional): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0, inplace=False)\n                          \t        (bnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t      (1): BlueLayer(\n                          \t        (convolutional): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0, inplace=False)\n                          \t        (bnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t      (2): BlueLayer(\n                          \t        (convolutional): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0.1, inplace=False)\n                          \t        (bnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t    )\n                          \t    (mpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n                          \t  )\n                          \t  (decoder3): DecoderBlock(\n                          \t    (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n                          \t    (decoder): Sequential(\n                          \t      (0): BlueLayer(\n                          \t        (convolutional): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0, inplace=False)\n                          \t        (bnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t      (1): BlueLayer(\n                          \t        (convolutional): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0, inplace=False)\n                          \t        (bnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t      (2): BlueLayer(\n                          \t        (convolutional): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0.1, inplace=False)\n                          \t        (bnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t    )\n                          \t  )\n                          \t  (decoder4): DecoderBlock(\n                          \t    (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n                          \t    (decoder): Sequential(\n                          \t      (0): BlueLayer(\n                          \t        (convolutional): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0, inplace=False)\n                          \t        (bnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t      (1): BlueLayer(\n                          \t        (convolutional): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0.1, inplace=False)\n                          \t        (bnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t    )\n                          \t  )\n                          \t  (decoder5): DecoderBlock(\n                          \t    (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n                          \t    (decoder): Sequential(\n                          \t      (0): BlueLayer(\n                          \t        (convolutional): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0, inplace=False)\n                          \t        (bnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t      (1): BlueLayer(\n                          \t        (convolutional): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0.1, inplace=False)\n                          \t        (bnorm): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t    )\n                          \t  )\n                          \t)\n2020-01-03 20:10:18.585201\tNumber of epochs 3000 with batch size: 3\n"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-4-fbce7d0cf32d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"local_data/prep_out.json\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_trainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marchitecture\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maugmentations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_every\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwith_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_every\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\asger\\Desktop\\alpha_cellari_imageseg\\src\\train.py\u001b[0m in \u001b[0;36mmodel_trainer\u001b[1;34m(self, architecture, learning_rate, augmentations, epochs, batch_size, val_every, with_loss, with_plot, with_accuracies_print, save_every)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m                                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m                                 \u001b[0mbatch_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m                                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                                 \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \"\"\"\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\"local_data/prep_out.json\", logger)\n",
        "net = trainer.model_trainer(architecture, learning_rate, augmentations, epochs, batch_size, val_every = 25, with_loss = False, save_every = 500)\n",
        "net.save('model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qrHbQtx-XY2O"
      },
      "source": [
        "\n",
        "## Evaluating the Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "G64U3ODUXY2Q"
      },
      "outputs": [],
      "source": [
        "from model import Net\n",
        "# Load model or use existing\n",
        "# net = Net.from_model(\"model\")\n",
        "tester = Tester(\"local_data/prep_out.json\", logger)\n",
        "tester.test_model(net, \"local_data/test\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b9S4CYyrXY2T"
      },
      "source": [
        "## Reconstructing the image\n",
        "\n",
        "In the following, a complete forwarding is carried out using oversampling to prevent borders at the croppings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "pkqZXm55XY2W"
      },
      "outputs": [],
      "source": [
        "from forward_passer import full_forward\n",
        "full_forward(net, None, True, \"local_data/full-forward.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "W0SI8vp4cOLN"
      },
      "outputs": [],
      "source": []
    }
  ]
}