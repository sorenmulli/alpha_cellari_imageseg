{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "colab": {
      "name": "imgseg.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qi3HPhhvXY1q"
      },
      "source": [
        "# Implementation of SegNet on Drone Images \n",
        "\n",
        "This notebook recreates the procedure of data preperation and data loading and also initializing, training and evaluating SegNet on this data.\n",
        "\n",
        "As the code is organized in modules, large portions of the produced code is not contained directly herein, but can be consulted by opening the `.py` files in the `src/`-folder.\n",
        "\n",
        "NOTE: Because the full network takes upwards of 30 GB of memory to train and evaluate, a simplified version is used here. The full version can be accessed by setting the `use_simple` variable to `False`. Runtime evaluation is also disabled by default to save memory. It is explained how to enable it further down."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\"Make sure that you are in /src before running this notebook\"\n'pwd' is not recognized as an internal or external command,\noperable program or batch file.\n2020-01-03 20:55:43.484879\tRunning full training loop\n\nTraceback (most recent call last):\n  File \"train.py\", line 156, in <module>\n    trainer = Trainer(\"local_data/prep_out.json\", logger)\n  File \"train.py\", line 32, in __init__\n    with open(json_path, encoding=\"utf-8\") as f:\nFileNotFoundError: [Errno 2] No such file or directory: 'local_data/prep_out.json'\n"
        }
      ],
      "source": [
        "!echo \"Make sure that you are in /src before running this notebook\"\n",
        "!pwd  # Prints current path (Linux and MacOS only)\n",
        "\n",
        "# For running on google colab\n",
        "# %cd /content\n",
        "# !git clone https://github.com/sorenmulli/alpha_cellari_imageseg.git\n",
        "# %cd alpha_cellari_imageseg/src\n",
        "# %mkdir logs\n",
        "# %pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Hw8PKduCXY14"
      },
      "source": [
        "## Data preperation\n",
        "\n",
        "Downloads and prepares data. This will take a number of minutes to run and requires a little over a gigabyte of storage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m pip install wget --user\n",
        "!python data_prepper.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tLEfk1FRXY2A"
      },
      "source": [
        "## Preparing network training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Configuring parameters...\n2020-01-03 20:52:00.773290\tRunning full training loop\n\nDone configuring\n"
        }
      ],
      "source": [
        "from logger import Logger\n",
        "from train import Trainer\n",
        "from model_test import Tester\n",
        "from augment import Augmenter, AugmentationConfig, flip_lr, flip_tb\n",
        "import torch\n",
        "\n",
        "print(\"Configuring parameters...\")\n",
        "\n",
        "# If True, a simpler version of segnet is used\n",
        "use_simple = True\n",
        "\n",
        "# Configuration of network architechture\n",
        "architecture = {\n",
        "\t\t\"kernel_size\":  3,\n",
        "\t\t\"padding\": 1, \n",
        "\t\t\"stride\": 1,\n",
        "\t\t\"pool_dims\": (2, 2),\n",
        "\t\t\"probs\": 0.1,\n",
        "\t\t\"reduce_complexity\": use_simple,\n",
        "}\n",
        "\n",
        "learning_rate = 1.5e-4\n",
        "batch_size = 3\n",
        "epochs = 3000\n",
        "\n",
        "# Configuration of data augmentation\n",
        "# Reducing cropsize significantly reduces memory usage and training time\n",
        "augmentations = AugmentationConfig(\n",
        "    augments =  [flip_lr, flip_tb],  \n",
        "    cropsize = (350, 350),\n",
        "    augment_p = [0.5, 0.5]\n",
        ")\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "logger = Logger(\"logs/train_run.log\", \"Running full training loop\")\n",
        "\n",
        "print(\"Done configuring\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3YOY6Z86XY2H"
      },
      "source": [
        "## Training the Network\n",
        "\n",
        "The following code trains the network.\n",
        "\n",
        "Because we had access to significant compute recourses, we did not optimize the loss calculations for memory. It is therefore not possible to run evaluation on most machines, so it is disabled by default. It can be enabled by setting the `with_loss` argument to `True`. The loss curve is available in the report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'local_data/prep_out.json'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-2-fbce7d0cf32d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"local_data/prep_out.json\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_trainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marchitecture\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maugmentations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_every\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwith_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_every\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\asger\\Desktop\\alpha_cellari_imageseg\\src\\train.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, json_path, logger)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m                 \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'local_data/prep_out.json'"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\"local_data/prep_out.json\", logger)\n",
        "net = trainer.model_trainer(architecture, learning_rate, augmentations, epochs, batch_size, val_every = 25, with_loss = False, save_every = 500)\n",
        "net.save('model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qrHbQtx-XY2O"
      },
      "source": [
        "\n",
        "## Evaluating the Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "G64U3ODUXY2Q"
      },
      "outputs": [],
      "source": [
        "from model import Net\n",
        "# Load model or use existing\n",
        "# net = Net.from_model(\"model\")\n",
        "tester = Tester(\"local_data/prep_out.json\", logger)\n",
        "tester.test_model(net, \"local_data/test\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b9S4CYyrXY2T"
      },
      "source": [
        "## Reconstructing the image\n",
        "\n",
        "In the following, a complete forwarding is carried out using oversampling to prevent borders at the croppings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "pkqZXm55XY2W"
      },
      "outputs": [],
      "source": [
        "from forward_passer import full_forward\n",
        "full_forward(net, None, True, \"local_data/full-forward.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "W0SI8vp4cOLN"
      },
      "outputs": [],
      "source": []
    }
  ]
}