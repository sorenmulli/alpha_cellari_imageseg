{"cells":[{"cell_type":"markdown","execution_count":3,"metadata":{},"outputs":[],"source":["# Implementation of SegNet on Drone Images \n","\n","This notebook recreates the procedure of data preperation and data loading and also initializing, training and evaluating SegNet on this data.\n","\n","As the code is organized in modules, large portions of the produced code is not contained directly herein, but can be consulted by opening the `.py` files in the `src/`-folder.\n","\n","NOTE: Because the full network takes upwards of 30 GB of memory to train and evaluate, a simplified version is used here. The full version can be accessed by setting the `use_simple` variable to `False`. Runtime evaluation is also disabled by default to save memory. It is explained how to enable it further down."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Make sure that you are in /src before running this notebook\n/home/asger/Desktop/alpha_cellari_imageseg/src\n"}],"source":["!echo \"Make sure that you are in /src before running this notebook\"\n","!pwd  # Prints current path (Linux and MacOS only)"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["## Data preperation\n","\n","Downloads and prepares data. This will take a number of minutes to run and requires a little over a gigabyte of storage."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Requirement already satisfied: wget in /home/asger/anaconda3/lib/python3.7/site-packages (3.2)\n2019-12-29 09:56:40.126691\tPreparation of data with images of shape (512, 512, 3)\n\n2019-12-29 09:56:40.126819\tDownloading images...\n2019-12-29 09:56:40.126883\tDone downloading images to paths\n                          \tlocal_data/raw.png\n                          \tlocal_data/target.png\n\n2019-12-29 09:56:40.126925\tLoading images...\n2019-12-29 09:56:42.401438\tDone loading images\n                          \tShapes: (6815, 5364, 3)\n                          \tSplit: (0.83, 0.17)\n\n2019-12-29 09:56:42.401571\tPadding images...\n2019-12-29 09:56:43.272500\tDone padding images\n                          \tShapes: (7168, 5632, 3)\n\n2019-12-29 09:56:43.272657\tSaving subimages to location local_data/imgs/{type}-{index}.png\n2019-12-29 09:56:59.591820\tDone saving subimages\n\n2019-12-29 09:56:59.592804\tStandardizing aerial image...\n2019-12-29 09:56:59.594032\tDone standardizing image\n\n2019-12-29 09:56:59.594258\tSqueezing target images to single channel...\n2019-12-29 10:01:15.062393\tDone creating target values.\n                          \tClasses including void (if any) last:\n                          \t000255000\n                          \t255000000\n                          \t255255000\n                          \t000000000\n\n2019-12-29 10:01:15.064041\tSplitting images...\n2019-12-29 10:01:16.655965\tDone splitting images\n                          \tNumber of images: 154\n                          \tShapes: (512, 512, 3)\n\n2019-12-29 10:01:16.656136\tDetecting void images...\n2019-12-29 10:01:16.785640\tDone finding voids\n                          \t46 images where voids\n\n2019-12-29 10:01:16.785811\tTransposing images to PyTorch's preferred format...\n2019-12-29 10:01:16.785915\tImages transposed. Shape: (154, 3, 512, 512)\n\n2019-12-29 10:01:16.786003\tSaving images...\n2019-12-29 10:01:30.147407\tSaved aerial images to 'local_data/aerial_prepared' and target images to 'local_data/target_prepared.npy'\n\n2019-12-29 10:01:30.147593\tSplitting images into train, validation, test, and voids...\n2019-12-29 10:01:30.151045\tDone splitting images\n                          \tTrain: 69 images\n                          \tValidation: 15 images\n                          \tTest: 24 images\n                          \tVoid: 46 images\n\n2019-12-29 10:01:30.151237\tSaving data preparation output...\n2019-12-29 10:01:30.152164\tDone saving output to 'local_data/prep_out.json'\n\n2019-12-29 10:01:30.152291\tDone preparing data\n\n"}],"source":["!python -m pip install wget\n","!python data_prepper.py"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["## Preparing network training\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Configuring parameters...\nDone configuring\n"}],"source":["from logger import Logger\n","from train import Trainer\n","from augment import Augmenter, AugmentationConfig, flip_lr, flip_tb\n","import torch\n","\n","print(\"Configuring parameters...\")\n","\n","# If True, a simpler version of segnet is used\n","use_simple = True\n","\n","# Configuration of network architechture\n","architecture = {\n","\t\t\"kernel_size\":  3,\n","\t\t\"padding\": 1, \n","\t\t\"stride\": 1,\n","\t\t\"pool_dims\": (2, 2),\n","\t\t\"probs\": 0.1,\n","\t\t\"reduce_complexity\": use_simple,\n","}\n","\n","learning_rate = 1.5e-4\n","batch_size = 3\n","epochs = 3000\n","\n","# Configuration of data augmentation\n","# Reducing cropsize significantly reduces memory usage and training time\n","augmentations = AugmentationConfig(\n","    augments =  [flip_lr, flip_tb],  \n","    cropsize = (350, 350),\n","    augment_p = [0.5, 0.5]\n",")\n","\n","torch.cuda.empty_cache()\n","print(\"Done configuring\")"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["## Training the Network\n","\n","The following code trains the network.\n","\n","Because we had access to significant compute recourses, we did not optimize the loss calculations for memory. It is therefore not possible to run evaluation on most machines, so it is disabled by default. It can be enabled by setting the `with_loss` argument to `True`. The loss curve is available in the report."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"2020-01-03 13:18:51.410141\tRunning full training loop\n\n2020-01-03 13:18:52.340897\tAugmentations: {'cropsize': (350, 350), 'augments': [<function flip_lr at 0x7f19f858ddd0>, <function flip_tb at 0x7f1a6ed6cc20>], 'augment_p': [0.5, 0.5]}\n2020-01-03 13:18:52.341221\tCriterion and optimizer: CrossEntropyLoss()\n                          \tAdam (\n                          \tParameter Group 0\n                          \t    amsgrad: False\n                          \t    betas: (0.9, 0.999)\n                          \t    eps: 1e-08\n                          \t    lr: 0.00015\n                          \t    weight_decay: 0\n                          \t)\n2020-01-03 13:18:52.540913\tTrain size: 69\n                          \tEval size: 15\n                          \tTest size: 24\n\n2020-01-03 13:18:52.541743\tNeural network information\n                          \t\tNet(\n                          \t  (encoder1): EncoderBlock(\n                          \t    (encoder): Sequential(\n                          \t      (0): BlueLayer(\n                          \t        (convolutional): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0, inplace=False)\n                          \t        (bnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t      (1): BlueLayer(\n                          \t        (convolutional): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0.1, inplace=False)\n                          \t        (bnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t    )\n                          \t    (mpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n                          \t  )\n                          \t  (encoder2): EncoderBlock(\n                          \t    (encoder): Sequential(\n                          \t      (0): BlueLayer(\n                          \t        (convolutional): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0, inplace=False)\n                          \t        (bnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t      (1): BlueLayer(\n                          \t        (convolutional): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0.1, inplace=False)\n                          \t        (bnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t    )\n                          \t    (mpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n                          \t  )\n                          \t  (encoder3): EncoderBlock(\n                          \t    (encoder): Sequential(\n                          \t      (0): BlueLayer(\n                          \t        (convolutional): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0, inplace=False)\n                          \t        (bnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t      (1): BlueLayer(\n                          \t        (convolutional): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0, inplace=False)\n                          \t        (bnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t      (2): BlueLayer(\n                          \t        (convolutional): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0.1, inplace=False)\n                          \t        (bnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t    )\n                          \t    (mpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n                          \t  )\n                          \t  (encoder4): EncoderBlock(\n                          \t    (encoder): Sequential(\n                          \t      (0): BlueLayer(\n                          \t        (convolutional): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0, inplace=False)\n                          \t        (bnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t      (1): BlueLayer(\n                          \t        (convolutional): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0, inplace=False)\n                          \t        (bnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t      (2): BlueLayer(\n                          \t        (convolutional): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0.1, inplace=False)\n                          \t        (bnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t    )\n                          \t    (mpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n                          \t  )\n                          \t  (decoder2): DecoderBlock(\n                          \t    (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n                          \t    (decoder): Sequential(\n                          \t      (0): BlueLayer(\n                          \t        (convolutional): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0, inplace=False)\n                          \t        (bnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t      (1): BlueLayer(\n                          \t        (convolutional): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0, inplace=False)\n                          \t        (bnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t      (2): BlueLayer(\n                          \t        (convolutional): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0.1, inplace=False)\n                          \t        (bnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t    )\n                          \t  )\n                          \t  (decoder3): DecoderBlock(\n                          \t    (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n                          \t    (decoder): Sequential(\n                          \t      (0): BlueLayer(\n                          \t        (convolutional): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0, inplace=False)\n                          \t        (bnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t      (1): BlueLayer(\n                          \t        (convolutional): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0, inplace=False)\n                          \t        (bnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t      (2): BlueLayer(\n                          \t        (convolutional): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0.1, inplace=False)\n                          \t        (bnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t    )\n                          \t  )\n                          \t  (decoder4): DecoderBlock(\n                          \t    (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n                          \t    (decoder): Sequential(\n                          \t      (0): BlueLayer(\n                          \t        (convolutional): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0, inplace=False)\n                          \t        (bnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t      (1): BlueLayer(\n                          \t        (convolutional): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0.1, inplace=False)\n                          \t        (bnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t    )\n                          \t  )\n                          \t  (decoder5): DecoderBlock(\n                          \t    (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n                          \t    (decoder): Sequential(\n                          \t      (0): BlueLayer(\n                          \t        (convolutional): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0, inplace=False)\n                          \t        (bnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t      (1): BlueLayer(\n                          \t        (convolutional): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                          \t        (dropout): Dropout(p=0.1, inplace=False)\n                          \t        (bnorm): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                          \t        (relu): ReLU()\n                          \t      )\n                          \t    )\n                          \t  )\n                          \t)\n2020-01-03 13:18:52.542124\tNumber of epochs 2 with batch size: 3\n"}],"source":["logger = Logger(\"logs/train_run.log\", \"Running full training loop\")\n","trainer = Trainer(\"local_data/prep_out.json\", logger)\n","net = trainer.model_trainer(architecture, learning_rate, augmentations, epochs, batch_size, val_every = 25, with_loss = False, save_every = 500)\n","net.save('model')"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["\n","## Evaluating the Network"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tester = Tester(\"local_data/prep_out.json\", logger)\n","tester.test_model(net, \"local_data/test\")\n"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["## Reconstructing the image\n","\n","In the following, a complete forwarding is carried out using oversampling to prevent borders at the croppings."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["full_forward(net, None, True, \"local_data/full-forward.png\")\n"]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.4"},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}